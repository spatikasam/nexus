<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NEXUS: Emotional Objects Clustering</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@200;300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
    
    <!-- PYODIDE for LIVE ML -->
    <script src="https://cdn.jsdelivr.net/pyodide/v0.26.2/full/pyodide.js"></script>
    
    <!-- FIREBASE (compat) -->
    <script src="https://www.gstatic.com/firebasejs/10.13.1/firebase-app-compat.js"></script>
    <script src="https://www.gstatic.com/firebasejs/10.13.1/firebase-firestore-compat.js"></script>
    <script src="https://www.gstatic.com/firebasejs/10.13.1/firebase-storage-compat.js"></script>
</head>
<body>
    <main class="page">
        <!-- HERO / INTRO BLOCK -->
        <header class="hero">
            <div class="hero-left">
                <h1 class="visually-hidden">NEXUS</h1>
                <img src="assets/nexus.png" alt="NEXUS logo" class="hero-logo">
                <p class="hero-lede">
                    A shared field of everyday objects annotated with six "universal" emotions.
                    Each contribution becomes a point in a live clustering experiment running entirely in the browser.
                </p>
                <div class="status-section">
                    <div class="status-pill" id="syncStatus">Initialising global datasetâ€¦</div>
                    <div class="utility-controls">
                        <button class="btn-ghost" onclick="downloadDataset()">Export ML dataset</button>
                        <button class="btn-ghost" onclick="showStats()">View stats</button>
                    </div>
                </div>
            </div>

            <!-- UPLOAD PANEL -->
            <div class="hero-right upload-card">
                <div class="section-label small">ADD OBJECT</div>
                <h2 class="panel-title">Contribute to the dataset</h2>
                <p class="panel-copy">
                    Select the emotion it carries for you, and send it into the shared space.
                </p>

                <!-- CLASSIC DRAG & DROP UPLOAD BOX -->
                <div class="upload-area" id="uploadArea">
                    <input type="file" id="imageInput" accept="image/*" style="display:none;">
                    <div class="upload-box">
                        <div class="upload-icon">ðŸ“¸</div>
                        <p class="upload-main-text">Choose an image & drop it here</p>
                        <p class="upload-subtext">PNG, JPG, GIF up to 10MB</p>
                        <label for="imageInput" class="browse-btn">Browse files</label>
                    </div>
                </div>

                <div class="emotion-row">
                    <select id="emotionSelect">
                        <option value="">Select emotion</option>
                        <option value="anger">Anger</option>
                        <option value="disgust">Disgust</option>
                        <option value="fear">Fear</option>
                        <option value="happiness">Happiness</option>
                        <option value="sadness">Sadness</option>
                        <option value="surprise">Surprise</option>
                    </select>
                    <button class="btn-solid upload-btn" onclick="submitEntry()">ADD TO NEXUS</button>
                </div>

                <div id="preview" class="preview"></div>
            </div>
        </header>

        <!-- PROMINENT CLUSTER BUTTON -->
        <section class="cluster-hero-section">
            <button onclick="runClustering()" class="cluster-hero-btn" id="clusterBtn" disabled>
                Cluster NEXUS (ML LIVE)
            </button>
        </section>

        <!-- STATS / ML STATUS -->
        <section id="stats" class="stats" style="display:none;"></section>
        <section id="ml-status" class="ml-status" style="display:none;"></section>

        <!-- GALLERY -->
        <section class="gallery-section">
            <div class="gallery-header">
                <div class="section-label small">DATASET VIEW</div>
                <h2>Global object field</h2>
                <p>
                    Each tile is an objectâ€“emotion pair. When clustering runs, borders reâ€‘colour to show the model's groupings.
                </p>
            </div>
            <div id="gallery" class="gallery"></div>
        </section>
    </main>

    <script>
        const firebaseConfig = {
            apiKey: "AIzaSyDc6m_tMPIAQS1pNzRCXyRJJo75-8M6fz4",
            authDomain: "nexus-emotions.firebaseapp.com",
            projectId: "nexus-emotions",
            storageBucket: "nexus-emotions.firebasestorage.app",
            messagingSenderId: "794178475232",
            appId: "1:794178475232:web:1e00f87111f4ba0e1aec85",
            measurementId: "G-TVVE5FS898"
        };

        firebase.initializeApp(firebaseConfig);
        const db = firebase.firestore();
        const storage = firebase.storage();
        
        let dataset = [];
        let pyodide = null;
        const emotions = ['anger', 'fear', 'disgust', 'happiness', 'sadness', 'surprise'];
        
        function getEmotionColor(emotion) {
            const colors = { 
                anger: '#ff4b5c', disgust: '#46c37b', fear: '#6b5bff',
                happiness: '#ffd166', sadness: '#4d7cff', surprise: '#ff66c4' 
            };
            return colors[emotion] || '#2657d6';
        }

        // DRAG & DROP
        const uploadArea = document.getElementById('uploadArea');
        const imageInput = document.getElementById('imageInput');

        ['dragenter', 'dragover', 'dragleave', 'drop'].forEach(eventName => {
            uploadArea.addEventListener(eventName, preventDefaults, false);
        });

        function preventDefaults(e) {
            e.preventDefault();
            e.stopPropagation();
        }

        ['dragenter', 'dragover'].forEach(eventName => {
            uploadArea.addEventListener(eventName, () => uploadArea.classList.add('drag-highlight'), false);
        });

        ['dragleave', 'drop'].forEach(eventName => {
            uploadArea.addEventListener(eventName, () => uploadArea.classList.remove('drag-highlight'), false);
        });

        uploadArea.addEventListener('drop', handleDrop, false);
        imageInput.addEventListener('change', handleFileSelect);

        function handleDrop(e) {
            const dt = e.dataTransfer;
            const files = dt.files;
            handleFiles(files);
        }

        function handleFileSelect() {
            handleFiles(imageInput.files);
        }

        function handleFiles(files) {
            const file = Array.from(files).find(f => f.type.startsWith('image/'));
            if (file && file.size <= 10 * 1024 * 1024) {
                const reader = new FileReader();
                reader.onload = (e) => showPreview(e.target.result, document.getElementById('emotionSelect').value);
                reader.readAsDataURL(file);
                imageInput.files = files;
            } else if (file && file.size > 10 * 1024 * 1024) {
                alert('File too large. Maximum 10MB.');
            }
        }

        async function syncDataset() {
            const statusEl = document.getElementById('syncStatus');
            try {
                statusEl.textContent = 'Syncing datasetâ€¦';
                statusEl.classList.add('status-loading');
                
                const snapshot = await db.collection('nexus')
                    .orderBy('timestamp', 'desc')
                    .limit(100)
                    .get();
                dataset = snapshot.docs.map(doc => ({ id: doc.id, ...doc.data() }));
                
                updateGallery();
                statusEl.textContent = `${dataset.length} images in NEXUS`;
                statusEl.classList.remove('status-loading');
                
                if (dataset.length >= 6) document.getElementById('clusterBtn').disabled = false;
            } catch (e) {
                statusEl.textContent = 'Firebase unavailable â€“ demo dataset loaded';
                statusEl.classList.remove('status-loading');
                dataset = Array(12).fill().map((_, i) => ({
                    id: i, emotion: emotions[i % 6], filename: `demo_${i}.jpg`,
                    imageURL: `https://picsum.photos/seed/${i}/110/110`
                }));
                updateGallery();
            }
        }

        async function submitEntry() {
            const file = imageInput.files[0];
            const emotion = document.getElementById('emotionSelect').value;
            
            if (!file || !emotion) {
                alert('Select an image and an emotion.');
                return;
            }
            
            const statusEl = document.getElementById('syncStatus');
            statusEl.textContent = 'Uploading imageâ€¦';
            statusEl.classList.add('status-loading');
            
            const reader = new FileReader();
            reader.onload = async (e) => {
                try {
                    const base64 = e.target.result.split(',')[1];
                    const storageRef = storage.ref(`nexus/${Date.now()}_${file.name}`);
                    await storageRef.putString(base64, 'base64');
                    const downloadURL = await storageRef.getDownloadURL();
                    
                    await db.collection('nexus').add({
                        emotion, filename: file.name, imageURL: downloadURL,
                        timestamp: firebase.firestore.FieldValue.serverTimestamp()
                    });
                    
                    showPreview(e.target.result, emotion);
                    imageInput.value = '';
                    document.getElementById('emotionSelect').value = '';
                    await syncDataset();
                } catch (err) {
                    alert('Upload failed â€“ check Firebase configuration.');
                    console.error(err);
                } finally {
                    statusEl.textContent = `${dataset.length} images in NEXUS`;
                    statusEl.classList.remove('status-loading');
                }
            };
            reader.readAsDataURL(file);
        }

        function showPreview(imageSrc, emotion) {
            const preview = document.getElementById('preview');
            preview.innerHTML = `
                <div class="preview-frame">
                    <img src="${imageSrc}" alt="preview">
                    <div class="preview-label">${emotion || 'pending label'}</div>
                </div>
            `;
        }

        function updateGallery() {
            const gallery = document.getElementById('gallery');
            gallery.innerHTML = dataset.map(entry => 
                `<button class="thumb" onclick="showDetail('${entry.id}')"
                         title="${entry.emotion || 'unknown'} â€“ ${entry.filename || 'demo'}">
                    <img src="${entry.imageURL || 'https://picsum.photos/seed/nexus/110/110'}"
                         alt="${entry.filename || 'object'}">
                </button>`
            ).join('');
        }

        function showDetail(id) {
            const entry = dataset.find(e => e.id === id);
            if (!entry) return;
            alert(`Emotion: ${entry.emotion}\nFile: ${entry.filename}\nID: ${entry.id}`);
        }

        function showStats() {
            const stats = document.getElementById('stats');
            const counts = {};
            dataset.forEach(e => {
                const key = e.emotion || 'unknown';
                counts[key] = (counts[key] || 0) + 1;
            });
            stats.innerHTML = `Total: ${dataset.length}<br>${Object.entries(counts)
                .map(([k,v]) => `${k}: ${v}`).join(' | ')}`;
            stats.style.display = (stats.style.display === 'none' || stats.style.display === '') ? 'block' : 'none';
        }

        async function downloadDataset() {
            const mlReady = dataset.map(entry => ({ ...entry }));
            const dataStr = JSON.stringify(mlReady, null, 2);
            const blob = new Blob([dataStr], {type: 'application/json'});
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `nexus-global-${new Date().toISOString().split('T')[0]}.json`;
            a.click();
        }

        async function initPyodide() {
            if (pyodide) return pyodide;
            const mlStatus = document.getElementById('ml-status');
            mlStatus.style.display = 'block';
            mlStatus.textContent = 'Loading Pyodide + scikit-learnâ€¦';
            
            pyodide = await loadPyodide();
            await pyodide.runPythonAsync(`
                import numpy as np
                from sklearn.cluster import KMeans
                from sklearn.decomposition import PCA
            `);
            
            mlStatus.textContent = 'ML engine ready.';
            return pyodide;
        }

        async function runClustering() {
            if (dataset.length < 6) {
                alert('Need at least 6 images before clustering.');
                return;
            }
            
            const py = await initPyodide();
            const mlStatus = document.getElementById('ml-status');
            mlStatus.style.display = 'block';
            mlStatus.textContent = 'Computing clustersâ€¦';
            
            const pixelData = await Promise.all(dataset.slice(0, 50).map(async (entry, idx) => {
                const img = new Image();
                img.crossOrigin = 'anonymous';
                img.src = entry.imageURL || `https://picsum.photos/seed/${idx}/110/110`;
                await new Promise(r => img.onload = r);
                
                const canvas = document.createElement('canvas');
                canvas.width = canvas.height = 64;
                const ctx = canvas.getContext('2d');
                ctx.drawImage(img, 0, 0, 64, 64);
                
                const imageData = ctx.getImageData(0, 0, 64, 64).data;
                const gray = [];
                for (let i = 0; i < imageData.length; i += 4) {
                    gray.push(imageData[i] * 0.3 + imageData[i+1] * 0.59 + imageData[i+2] * 0.11);
                }
                return gray;
            }));
            
            const result = await py.runPythonAsync(`
                X = np.array(${JSON.stringify(pixelData)})
                X = X.reshape(-1, 4096)
                X = X / 255.0
                
                pca = PCA(n_components=50)
                X_pca = pca.fit_transform(X)
                
                kmeans = KMeans(n_clusters=6, random_state=42, n_init=10, max_iter=100)
                clusters = kmeans.fit_predict(X_pca)
                
                {"clusters": clusters.tolist()}
            `);
            
            const clusters = result.clusters.toJs();
            const thumbs = document.querySelectorAll('.thumb');
            
            clusters.forEach((cluster, i) => {
                if (!thumbs[i]) return;
                const emotion = emotions[cluster];
                thumbs[i].style.borderColor = getEmotionColor(emotion);
                thumbs[i].classList.add('thumb-clustered');
                thumbs[i].title = `${dataset[i]?.emotion || 'unknown'} â†’ ML: ${emotion} (cluster ${cluster})`;
            });
            
            mlStatus.textContent = `Live ML clustering completed for ${dataset.length} images.`;
            document.getElementById('gallery').classList.add('gallery-clustered');
        }

        // Initialise
        syncDataset();
        setInterval(syncDataset, 10000);
    </script>
</body>
</html>
